# Alignment Research Portfolio

Welcome! This repository serves as the central hub for my AI alignment research portfolio, highlighting projects on model behavior, robustness, interpretability, and retrieval-augmented workflows.

## About Me

I am a senior software engineer transitioning into AI research and alignment. Over the past year, I have focused on designing and evaluating AI systems, building prototypes that explore model reliability, agentic workflows, and human-in-the-loop evaluation.

## Planned Research Prototypes

| Project | Description | Status |
|---------|-------------|--------|
| **RAG Evaluation Framework** | A retrieval-augmented generation (RAG) experiment to measure retrieval quality, response fidelity, and hallucination behavior across different embeddings and prompting strategies. | In progress |
| **Multi-Agent Interpretability Demo** | A prototype exploring agent interactions and decision-making transparency, designed to evaluate model reasoning and emergent behaviors in controlled multi-agent workflows. | Scheduled |
| **Robustness Benchmark Suite** | A set of experiments to stress-test model performance under distribution shifts, prompt perturbations, and adversarial inputs, with metrics for reliability, calibration, and error analysis. | Scheduled |

## Contact

For questions or collaboration, reach me via [GitHub](https://github.com/jsandino).

---

*Note: This portfolio is a curated selection of active research projects. Archived repositories are maintained for historical reference only.*
